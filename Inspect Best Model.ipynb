{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"dir_dataset\": Path(\"./clean_dataset\"),\n",
    "    \"dir_images\": Path(\"./clean_dataset/images\"),\n",
    "    \"trained_weights\": \"resnet34_unfreeze_img_size_252_DDD-36\",\n",
    "    \"validation_set\": \"valid.txt\",\n",
    "    \"model\": models.resnet34,\n",
    "    \"metric\": [error_rate, accuracy],\n",
    "    \"img_size\": 252,\n",
    "    \"batch_size\": 64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting label information out of train file name\n",
    "# Example: p002_c0_img_3370 -> c0\n",
    "get_y_fn = lambda x: x.stem.split(\"_\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Databunch\n",
    "data = (ImageList.from_folder(CONFIG[\"dir_dataset\"])\n",
    "        .split_by_fname_file(CONFIG[\"validation_set\"])\n",
    "        .label_from_func(get_y_fn)\n",
    "        .transform(get_transforms(do_flip=False), size=CONFIG[\"img_size\"])\n",
    "        .databunch(bs=CONFIG[\"batch_size\"])\n",
    "        .normalize(imagenet_stats)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, CONFIG[\"model\"], metrics=CONFIG[\"metric\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(CONFIG[\"trained_weights\"]) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_gradients_plot(model, input_img, target, cmap, n_steps=50):\n",
    "    integrated_gradients = IntegratedGradients(model)\n",
    "    attributions_ig = integrated_gradients.attribute(input_img,\n",
    "                                                     target=target, n_steps=n_steps)\n",
    "\n",
    "    _ = viz.visualize_image_attr(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                 np.transpose(input_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                 method='heat_map',\n",
    "                                 cmap=cmap,\n",
    "                                 show_colorbar=True,\n",
    "                                 sign='positive',\n",
    "                                 outlier_perc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_shap_plot(model, input_img, target, cmap, n_samples=50):\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    gradient_shap = GradientShap(model)\n",
    "\n",
    "    # Defining baseline distribution of images\n",
    "    rand_img_dist = torch.cat([input_img * 0, input_img * 1])\n",
    "\n",
    "    attributions_gs = gradient_shap.attribute(input_img,\n",
    "                                              n_samples=n_samples,\n",
    "                                              stdevs=0.0001,\n",
    "                                              baselines=rand_img_dist,\n",
    "                                              target=target)\n",
    "    \n",
    "    _ = viz.visualize_image_attr_multiple(np.transpose(attributions_gs.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                          np.transpose(input_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                          [\"original_image\", \"heat_map\"],\n",
    "                                          [\"all\", \"absolute_value\"],\n",
    "                                          cmap=cmap,\n",
    "                                          show_colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occlusion_plot(model, input_img, target):\n",
    "    occlusion = Occlusion(learn.model)\n",
    "\n",
    "    rand_img_dist = torch.cat([input_img * 0, input_img * 1])\n",
    "    attributions_occ = occlusion.attribute(input_img,\n",
    "                                           strides = (3, 50, 50),\n",
    "                                           target=target,\n",
    "                                           sliding_window_shapes=(3,60, 60),\n",
    "                                           baselines=0)\n",
    "\n",
    "    _ = viz.visualize_image_attr_multiple(np.transpose(attributions_occ.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                          np.transpose(input_img.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                                          [\"original_image\", \"heat_map\"],\n",
    "                                          [\"all\", \"positive\"],\n",
    "                                          show_colorbar=True,\n",
    "                                          outlier_perc=2,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "neptune": {
   "notebookId": "5652d2de-f4f7-43c6-aeed-a3d6aa311440"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
